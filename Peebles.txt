REFERENCE:
Peebles, Peyton Z. Jr. "Chapter 1 Probability." In _Probability, Random Variables, and Random Signal Principles_. 4th ed. New York: McGraw-Hill Inc. 2001.

GENERAL:
p. 1 - 40

NOTES:

OUTLINE:
I.   Introduction
  i.   This book introduces probability using two approaches (p. 2)
  ii.  Frequency definition of probabilty gives a degree of physical insight which is popular with engineers, and is often used in texts having principal topics other than probability theory iteself (p. 2)
  iii. The second approach uses set theory (p. 3)
II.  Set Definitions
  i.   If a is an element of set A, we write $a \in A$ (p. 3)
  ii.  If a is not an element of set A, we write $a \notin A$ (p. 3)
  iii. A set is said to be countable if its elements can be put in one-to-one correspondence with the natural numbers, which are the integers 1, 2, 3, etc (p. 3)
  iv.  If a set is not countable, it is called uncountable (p. 3)
  v.   A set is said to be empty if it has no elements and is written $\emptyset$ (p. 3)
  vi.  A finite set is one that is either empty or has elements that can be counted (p. 3)
  v.   If a set is not finite, it is called infinite (p. 3)
  vi.  An infinite set having countable elements is called countably infinite (p. 3)
  vii. If a set A is a subset of B we write $A \subseteq B$ (p. 3)
  viii. If at least one element exists in B which is not in A, then A is a proper subset of B, written as $A \subset B$ (p. 3)
  ix.  Two sets, A and B, are called disjoint or mutually exclusive if they have no common elements (p. 4)
III. Set Operations
  A. Venn Diagram (p. 5)
  B. Equality and Difference (p. 5 - 6)
    i.   Two sets A and B are equal if all elements in A are present in B and all elements in B are present in A (p. 5)
    ii.  The difference of two sets A and B, denoted $A - B$, is the set containing all elements of A that are not present in B (p. 6)
  C. Union and Intersection (p. 6)
    i.   The union (call it C) of two sets A and B is written $$C = A \cup B$$ (p. 6)
    ii.  It is the set of all elements of A or B or both (p. 6)
    iii. The union is sometimes called the sum of two sets (p. 6)
    iv.  The intersection (call it D) of two sets A and B is written $$D = A \cap B$$ (p. 6)
  D. Complement (p. 6 - 7)
    i.   The complement of a set A, denoted by $\bar{A}$, is the set of all elements not in A (p. 6)
    ii.  $$\bar{A} = S - A$$
    iii. Other identities: $$\bar{\emptyset} = S$$; $$\bar{S} = \emptyset$$; $$A \cup \bar{A} = S$$; and $$A \cap \bar{A} = \emptyset$$
  E. Algebra of Sets (p. 7)
    i.   The cummutative law: $$A \cap B = B \cap A$$; $$A \cup B = B \cup A$$ (p. 7)
    ii.  The distributive law: $$A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$$; $$A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$$ (p. 7)
    iii. The associative law: $$(A \cup B) \cup C = A \cup (B \cup C) = A \cup B \cup C$$; $$(A \cap B) \cap C = A \cap (B \cap C) = A \cap B \cap C$$ (p. 7)
  F. De Morgan's Laws (p. 8)
    i.   $$(\overline{A \cup B}) = \bar{A} \cap \bar{B}$$; $$(\overline{A \cap B}) = \bar{A} \cup \bar{B}$$ (p. 8)
  G. Duality Principle (p. 8)
    i.   If in an identiy we replace unions by intersections, intersections by unions, S by $\emptyset$, and $\emptyset$ by S, then the identity is preserved (p. 8)
    ii.  For example: sine $A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$ then it follows that $A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$ (p. 8) 
IV.  Probability introduced through Sets and Relative Frequency (p. 9)
  i.   This introduces probability through set theory and relative frequency (p. 9)
  ii.  Set theory is more sound of the two (p. 9)
  A. Experiments and Sample Spaces (p. 9)
  i.   The set of all possible outcomes in any given experiment is called the sample space (p. 9)
  ii.  The sample space is the first of three elements in our mathematical model of experiments, the remaing elements are events and probability (p. 9)
  B. Discrete and Continuous Sample Spaces (p. 9 - 10)
  i.   Sample spaces can be discrete/continuous and finite/infinite (p. 9 - 10)
  C. Events
  D. Probability Definition and Axioms
  E. Mathematical Model of Experiments
  F. Probability as a Relative Frequency
V. Joint and Conditional Probability
  A. Joint Probability
  B. Conditional Probability
  C. Total Probabilty
  D. Bayes' Theorem
VI.  Independent Events
  A. Two Events
  B. Multiple Events
  C. Properties of Independent Events
VII. Combined Experiments
  A. Combined Sample Space
  B. Events on the Combined Space
  C. Probabilities
  D. Permutations
  E. Combinations
VIII. Bernoulli Trials